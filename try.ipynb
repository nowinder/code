{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99915ee7-2415-49d1-a929-89a11316b6de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (((None, 128, 128), (None, 128, 128)), (None, 128, 128, 2)), types: ((tf.float32, tf.float32), tf.float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import imageio.v2 as imageio\n",
    "import os\n",
    "import numpy as np\n",
    "from keras import backend as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "def getimg(dir,j):\n",
    "    input_dir = dir\n",
    "    img_list = []\n",
    "    for i in range(1+j,901+j):\n",
    "        filename = f'{i}.tif'\n",
    "        img_path = os.path.join(input_dir,filename)\n",
    "        img = imageio.imread(img_path)\n",
    "        img = img.astype(np.float32)\n",
    "        img = img / 255.0\n",
    "        img_list.append(img)\n",
    "    return img_list\n",
    "def onehot(img):\n",
    "    img = tf.cast(img, tf.int32)\n",
    "    img_one_hot = tf.one_hot(img, depth=2, on_value=255.0, off_value=0.0, axis=-1)\n",
    "    return img_one_hot\n",
    "def add_channel(img): \n",
    "    img = tf.expand_dims(img, axis=-1) \n",
    "    return img\n",
    "label_list=getimg(dir='/data/caizhizheng/2D/v2/label/label',j=0)\n",
    "label_dataset = tf.data.Dataset.from_tensor_slices(label_list)\n",
    "label_dataset = label_dataset.map(onehot)\n",
    "img1_list=getimg(dir='/data/caizhizheng/2D/v2/data1/data',j=0)\n",
    "img1_dataset = tf.data.Dataset.from_tensor_slices(img1_list)\n",
    "# img1_dataset = img1_dataset.map(add_channel)\n",
    "img2_list=getimg(dir='/data/caizhizheng/2D/v2/data2/data',j=900)\n",
    "img2_dataset = tf.data.Dataset.from_tensor_slices(img2_list)\n",
    "# img2_dataset = img2_dataset.map(add_channel)\n",
    "image_dataset = tf.data.Dataset.zip((img1_dataset, img2_dataset))\n",
    "train_dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(32)\n",
    "train_dataset\n",
    "# gen_data=labe_dataset.batch(32)\n",
    "# for batch in gen_data.take(1):\n",
    "#     print([arr.numpy() for arr in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bf4d7eb-aacf-4696-9e81-bf4eaa478d81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load 2.5Dv3.py\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from unittest import result\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.optimizer_v2.adam import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.saving.utils_v1.mode_keys import is_train\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import imageio.v2 as imageio\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dropout, AveragePooling2D, concatenate, \\\n",
    "    GlobalAveragePooling2D, MaxPooling2D, Dense, Input\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "import zipfile\n",
    "import evalu\n",
    "import time\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "# Read datasets\n",
    "def getimg(dir,j):\n",
    "    input_dir = dir\n",
    "    img_list = []\n",
    "    for i in range(1+j,901+j):\n",
    "        filename = f'{i}.tif'\n",
    "        img_path = os.path.join(input_dir,filename)\n",
    "        img = imageio.imread(img_path)\n",
    "        img = img.astype(np.float32)\n",
    "        img = img / 255.0\n",
    "        img_list.append(img)\n",
    "    return img_list\n",
    "\n",
    "def onehot(img):\n",
    "    img = tf.cast(img, tf.int32)\n",
    "    img_one_hot = tf.one_hot(img, depth=2, on_value=1.0, off_value=0.0, axis=-1)\n",
    "    return img_one_hot\n",
    "\n",
    "def add_channel(img): \n",
    "    img = tf.expand_dims(img, axis=-1) \n",
    "    return img         \n",
    "\n",
    "# Draw loss curve\n",
    "def plot_history(history, result_dir, prefix):\n",
    "    \"\"\"\n",
    "    将训练与验证的accuracy与loss画出来\n",
    "    \"\"\"\n",
    "    plt.plot(history.history['accuracy'], marker='.')\n",
    "    plt.plot(history.history['val_accuracy'], marker='.')\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.grid()\n",
    "    plt.legend(['acc', 'val_acc'], loc='upper right')\n",
    "\t# plt.show()\n",
    "    plt.savefig('/code/loss_picture/unet_val_ace.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(history.history['loss'], marker='.')\n",
    "    plt.plot(history.history['val_loss'], marker='.')\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.grid()\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper right')\n",
    "    # plt.show()\n",
    "    plt.savefig('/code/loss_picture/denseunet_loss.png')\n",
    "    plt.close()\n",
    "\n",
    "    # x = history.history['loss']\n",
    "    # np.savetxt('D:/pycharm/up_down_code/loss_picture/unet_train_loss.txt', x, fmt='%f')\n",
    "    # y = history.history['val_loss']\n",
    "    # np.savetxt('D:/pycharm/up_down_code/loss_picture/unet_val_loss.txt', y, fmt='%f')hb\n",
    "\n",
    "\n",
    "def Conv_Block(input_tensor, filters, bottleneck=False, weight_decay=1e-4):\n",
    "    \"\"\"    封装卷积层\n",
    "\n",
    "    :param input_tensor: 输入张量\n",
    "    :param filters: 卷积核数目\n",
    "    :param bottleneck: 是否使用bottleneck\n",
    "    :param dropout_rate: dropout比率\n",
    "    :param weight_decay: 权重衰减率\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    concat_axis = 1 if K.image_data_format() == 'channel_first' else -1  # 确定格式\n",
    "\n",
    "    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(input_tensor)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # if bottleneck:\n",
    "    #     # 使用bottleneck进行降维\n",
    "    #     inter_channel = filters\n",
    "    #     x = Conv2D(inter_channel, (1, 1),\n",
    "    #                kernel_initializer='he_normal',\n",
    "    #                padding='same', use_bias=False,\n",
    "    #                kernel_regularizer=l2(weight_decay))(x)\n",
    "    #     x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n",
    "    #     x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters, (3, 3), kernel_initializer='he_normal', padding='same', use_bias=False)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def dens_block(input_tensor, nb_filter):\n",
    "    x1 = Conv_Block(input_tensor, nb_filter)\n",
    "    add1 = concatenate([x1, input_tensor], axis=-1)\n",
    "    x2 = Conv_Block(add1, nb_filter)\n",
    "    add2 = concatenate([x1, input_tensor, x2], axis=-1)\n",
    "    x3 = Conv_Block(add2, nb_filter)\n",
    "    return x3\n",
    "\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "# model definition\n",
    "def unet(input_shape=(128, 128, 2)):\n",
    "    # tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    # inputs = Input(input_shape)\n",
    "    input1=Input(shape=(128,128,1))\n",
    "    input2=Input(shape=(128,128,1))\n",
    "    inputs=Concatenate(axis=-1)([input1,input2])\n",
    "    # x  = Conv2D(32, 1, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = Conv2D(32, 7, kernel_initializer='he_normal', padding='same', strides=1, use_bias=False,\n",
    "               kernel_regularizer=l2(1e-4))(inputs)\n",
    "    # down first\n",
    "    down1 = dens_block(x, nb_filter=64)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(down1)  # 256\n",
    "    # down second\n",
    "    down2 = dens_block(pool1, nb_filter=64)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(down2)  # 128\n",
    "    # down third\n",
    "    down3 = dens_block(pool2, nb_filter=128)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(down3)  # 64\n",
    "    # down four\n",
    "    down4 = dens_block(pool3, nb_filter=256)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(down4)  # 32\n",
    "    # center\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    # up first\n",
    "    up6 = UpSampling2D(size=(2, 2))(drop5)\n",
    "    # up6 = UpSampling2D(size=(2, 2))(drop5)\n",
    "    add6 = concatenate([down4, up6], axis=3)\n",
    "    up6 = dens_block(add6, nb_filter=256)\n",
    "    # up second\n",
    "    up7 = UpSampling2D(size=(2, 2))(up6)\n",
    "    # up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    add7 = concatenate([down3, up7], axis=3)\n",
    "    up7 = dens_block(add7, nb_filter=128)\n",
    "    # up third\n",
    "    up8 = UpSampling2D(size=(2, 2))(up7)\n",
    "    # up8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    add8 = concatenate([down2, up8], axis=-1)\n",
    "    up8 = dens_block(add8, nb_filter=64)\n",
    "    # up four\n",
    "    up9 = UpSampling2D(size=(2, 2))(up8)\n",
    "    add9 = concatenate([down1, up9], axis=-1)\n",
    "    up9 = dens_block(add9, nb_filter=64)\n",
    "    # output\n",
    "    conv10 = Conv2D(32, 7, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(up9)\n",
    "    conv10 = Conv2D(2, 1, activation='softmax')(conv10)\n",
    "    model = Model(inputs=[input1,input2], outputs=conv10)\n",
    "    # print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "# define Huber loss\n",
    "def huber_loss(y_true, y_pred):\n",
    "    return tf.losses.huber_loss(y_true, y_pred, delta=0.01)\n",
    "\n",
    "\n",
    "def simm_loss(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true)) + 0.01 * K.mean(K.abs(y_pred))\n",
    "    # return tf.abs(tf.norm(y_pred - y_true))/tf.norm(y_true)\n",
    "    \n",
    "# smooth = 1. # 用于防止分母为0.\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true) # 将 y_true 拉伸为一维.\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (K.sum(y_true_f * y_true_f) + K.sum(y_pred_f * y_pred_f))\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1. - dice_coef(y_true, y_pred)\n",
    "\n",
    "# Define the learning rate attenuation value\n",
    "def scheduler(epoch):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.1)\n",
    "        print(\"lr change to {}\".format(lr * 0.1))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "\n",
    "# ssim psnr\n",
    "from ssim import compute_ssim\n",
    "import math\n",
    "\n",
    "\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean((img1 / 255. - img2 / 255.) ** 2)\n",
    "    if mse < 1.0e-10:\n",
    "        return 100\n",
    "    PIXEL_MAX = 1\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "def add_gaussian_nois(image_in, mean=0, var=0.01):\n",
    "    \"\"\"\n",
    "    给图片添加高斯噪声\n",
    "    \"\"\"\n",
    "    img = image_in.astype(np.int16)\n",
    "    mu = 0\n",
    "    sigma = 40\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            for k in range(img.shape[2]):\n",
    "                img[i, j, k] = img[i, j, k] + random.gauss(mu=mu, sigma=sigma)\n",
    "    img[img > 255] = 255\n",
    "    img[img < 0] = 0\n",
    "    img_out = img.astype(np.uint8)\n",
    "\n",
    "    # cv2.imshow(\"noise_image\",img_out)\n",
    "    # cv2.waitKey(0)\n",
    "    return img_out\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "  0.001,\n",
    "  decay_steps=10,\n",
    "  decay_rate=1,\n",
    "  staircase=False)\n",
    "def train(model):\n",
    "    # train\n",
    "    # tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    # no shutil and shutil module\n",
    "    # logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "    # shutil.rmtree(logdir, ignore_errors=True)\n",
    "    # use tf.io.gfile\n",
    "    # logdir = tf.io.gfile.mkdir('/tensorboard_logs')\n",
    "    # tf.io.gfile.rmtree (logdir)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr_schedule), loss=dice_coef_loss, metrics=['accuracy'])\n",
    "    # reduce_lr = LearningRateScheduler(scheduler)\n",
    "    # reduce_lr = LearningRateScheduler(lschedule)\n",
    "    model_checkpoint = ModelCheckpoint('/code/save_model/'+model_savename, monitor='loss', verbose=1,\n",
    "                                       save_best_only=True)\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "    Board = tf.keras.callbacks.TensorBoard(log_dir=\"/output/logs\")\n",
    "\n",
    "    history = model.fit(train_dataset.repeat(),\n",
    "                                  steps_per_epoch=100,\n",
    "                                  epochs=400,\n",
    "                                  validation_data=validation_dataset,\n",
    "                                #   validation_steps=50,\n",
    "                                  callbacks=[model_checkpoint,\n",
    "                                             early_stop,Board\n",
    "                                             ])\n",
    "    plot_history(history, '.results/', 'Unet')\n",
    "    return model\n",
    "\n",
    "def test(model):\n",
    "    # test\n",
    "    input_dir1 = '/data/caizhizheng/2D/v2/data1/data'\n",
    "    input_dir2 = '/data/caizhizheng/2D/v2/data2/data'\n",
    "    n = len(os.listdir(input_dir1))\n",
    "    for i in range(1,n+1):\n",
    "        # x = cv2.imread('/data/caizhizheng/data/test/%d.tif' % (i))  # #The absolute path of the testsets\n",
    "        # x = add_gaussian_nois(x)\n",
    "        # x = cv2.cvtColor(x,cv2.COLOR_BGR2GRAY)\n",
    "        filename1 = f'{i}.tif'\n",
    "        img_path1 = os.path.join(input_dir1,filename1)\n",
    "        x1 = cv2.imread(img_path1, cv2.IMREAD_GRAYSCALE)\n",
    "        x1 = x1 / 255.0\n",
    "        x1 = np.array([x1])\n",
    "        filename2 = f'{i+n}.tif'\n",
    "        img_path2 = os.path.join(input_dir2,filename2)\n",
    "        x2 = cv2.imread(img_path2, cv2.IMREAD_GRAYSCALE)\n",
    "        x2 = x2 / 255.0\n",
    "        x2 = np.array([x2])\n",
    "        # xt = np.stack([x1, x2], axis=-1)\n",
    "        mask_tensor = model.predict([x1,x2], batch_size=None, verbose=0, steps=None)\n",
    "        mask = mask_tensor[0]\n",
    "        mask = tf.argmax(mask, axis=-1)\n",
    "        mask = tf.keras.backend.eval(mask)\n",
    "        mask = (mask * 255).astype(np.uint8)\n",
    "        cv2.imwrite('/data/caizhizheng/2D/v2/temp_result/%d.tif' % (i), mask)\n",
    "        \n",
    "def make_zip(source_dir, output_name):\n",
    "    zipf = zipfile.ZipFile(output_name, 'w')\n",
    "    prelen = len(os.path.dirname(source_dir))\n",
    "    for parent, _, filenames in os.walk(source_dir):\n",
    "        for filename in filenames:\n",
    "            pathfile = os.path.join(parent, filename)\n",
    "            arcname = pathfile[prelen:].strip(os.path.sep)     #相对路径\n",
    "            zipf.write(pathfile, arcname)\n",
    "        zipf.close()\n",
    "BATCH_SIZE=128\n",
    "if __name__ == '__main__':\n",
    "    # is_train = False # you can change this to False if you want to test only\n",
    "    model = unet(input_shape=(128, 128, 2))\n",
    "    # model = tf.keras.models.load_model('/code/save_model/dens_2.5Dv3.keras')\n",
    "    # if is_train:\n",
    "    label_list=getimg(dir='/data/caizhizheng/2D/v2/label/label',j=0)\n",
    "    label_dataset = tf.data.Dataset.from_tensor_slices(label_list)\n",
    "    label_dataset = label_dataset.map(onehot)\n",
    "    img1_list=getimg(dir='/data/caizhizheng/2D/v2/data1/data',j=0)\n",
    "    img1_dataset = tf.data.Dataset.from_tensor_slices(img1_list)\n",
    "    img2_list=getimg(dir='/data/caizhizheng/2D/v2/data2/data',j=900)\n",
    "    img2_dataset = tf.data.Dataset.from_tensor_slices(img2_list)\n",
    "    image_dataset = tf.data.Dataset.zip((img1_dataset, img2_dataset))\n",
    "    image_dataset = image_dataset.map(lambda x, y: [x, y])\n",
    "    model.load_weights('/code/save_model/dens_2.5Dv3.keras') # load the saved weights\n",
    "    test(model) # test the model and save the results\n",
    "    # mask = model.predict(image_dataset, batch_size=32, steps=None)\n",
    "    # mask = maskb[0]\n",
    "    # mask = tf.argmax(mask, axis=-1)\n",
    "    # mask = tf.keras.backend.eval(mask)\n",
    "    # mask = (mask * 255).astype(np.uint8)\n",
    "    # for i in range(0, len(mask)+1):\n",
    "    #     cv2.imwrite('/data/caizhizheng/2D/v2/result/%d.tif' % (i), mask[i])\n",
    "    # make_zip(source_dir=source_dir, output_name=output_name)\n",
    "    # print(\"zip OK\")\n",
    "    # evalu.main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f48e23d-779b-47f9-80bd-415b787f14c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(128, 128), dtype=tf.float32, name=None), TensorSpec(shape=(128, 128), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "source": [
    "print(image_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebd0e544-e15e-40ed-a4a2-7c3bad906e90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([900   2 128 128], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.shape(dataset_to_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19ef2ad8-2608-4c9a-be01-c0399c2c42c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450.0\n"
     ]
    }
   ],
   "source": [
    "input_dir1 = '/data/caizhizheng/2D/v2/data1/data'\n",
    "number = len(os.listdir(input_dir1))\n",
    "number = number/2\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17418878-1bc8-468b-8746-5fd323d0476c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evalu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbbdbd15-bbff-493d-924b-951a850b2d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均汉明距离为：330.4622\n",
      "平均杰卡德相似系数为：0.8829\n",
      "平均Dice相似系数为：0.9271\n",
      "平均误差为：32.9223%\n"
     ]
    }
   ],
   "source": [
    "# %load evalu.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "def main(output_dir='', label_dir=''):\n",
    "    # 定义一个空列表存储n个误差\n",
    "    errors = []\n",
    "    # 定义三个空列表存储n个汉明距离、杰卡德相似系数和Dice相似系数\n",
    "    hamming_distances = []\n",
    "    jaccard_similarities = []\n",
    "    dice_similarities = []\n",
    "    n = len((os.listdir(output_dir)))\n",
    "            \n",
    "    # 用一个for循环遍历n张图像\n",
    "    for i in range(1, n+1):\n",
    "        output = cv2.imread(output_dir+f'{i}.tif', cv2.IMREAD_UNCHANGED)\n",
    "        label = cv2.imread(label_dir+f'{i}.tif', cv2.IMREAD_UNCHANGED)\n",
    "        output = output / 255.0\n",
    "        label = label / 255.0\n",
    "        output = output.astype(int)\n",
    "        label = label.astype(int)\n",
    "        # 调用error函数计算两个图像之间的误差，并添加到列表中\n",
    "        errors.append(error(output, label))\n",
    "        # 调用三个函数，计算两个图像之间的三个参数，并添加到对应的列表中\n",
    "        hamming_distances.append(hamming_distance(output, label))\n",
    "        jaccard_similarities.append(jaccard_similarity(output, label))\n",
    "        dice_similarities.append(dice_similarity(output, label))\n",
    "    # 计算100个误差的平均值，忽略-1的值\n",
    "    mean_error = np.mean([e for e in errors if e != -1])\n",
    "    # 计算三个参数的平均值，忽略-1的值，并打印出来\n",
    "    mean_hamming_distance = np.mean([h for h in hamming_distances if h != -1])\n",
    "    mean_jaccard_similarity = np.mean([j for j in jaccard_similarities if j != -1])\n",
    "    mean_dice_similarity = np.mean([d for d in dice_similarities if d != -1])\n",
    "    print(f'平均汉明距离为：{mean_hamming_distance:.4f}')\n",
    "    print(f'平均杰卡德相似系数为：{mean_jaccard_similarity:.4f}')\n",
    "    print(f'平均Dice相似系数为：{mean_dice_similarity:.4f}')\n",
    "    # 打印平均误差\n",
    "    print(f'平均误差为：{mean_error:.4f}%')\n",
    "\n",
    "    # 将100个误差写入csv文件，假设文件名为errors.csv，位于当前目录下\n",
    "    timestamp = time.strftime('%Y%m%d%H%M')\n",
    "    filename = 'errors_'+ timestamp +'.csv'\n",
    "    with open(filename, 'w') as f:\n",
    "        # 创建一个csv写入对象\n",
    "        writer = csv.writer(f)\n",
    "        # 写入一行表头，表示图像编号和误差\n",
    "        writer.writerow(['Image', 'Error', 'Hamming Distance', 'Jaccard Similarity', 'Dice Similarity'])\n",
    "        writer.writerow(['Mean', mean_error, mean_hamming_distance, mean_jaccard_similarity, mean_dice_similarity])\n",
    "        # 用一个for循环遍历n个误差，并写入一行数据，表示第i张图像的误差\n",
    "        for i, (e,h,j,d) in enumerate(zip(errors,hamming_distances, jaccard_similarities, dice_similarities)):\n",
    "            writer.writerow([i + 1, e,h,j,d])\n",
    "# 定义一个函数计算两个图片矩阵的误差\n",
    "def error(img1, img2):\n",
    "    # 将图片矩阵转换为一维向量\n",
    "    vec1 = img1.flatten()\n",
    "    vec2 = img2.flatten()\n",
    "    # 计算两个向量的差值的二范数的绝对值\n",
    "    diff = np.linalg.norm(vec1 - vec2)\n",
    "    # 计算真值向量的二范数\n",
    "    norm = np.linalg.norm(vec2)\n",
    "    # 返回误差，即差值除以真值\n",
    "        # 判断真值向量是否为0或接近0\n",
    "    if norm < 1e-6:\n",
    "        # 返回一个特殊的值，表示无法计算误差\n",
    "        return -1\n",
    "    else:\n",
    "        # 返回误差，即差值除以真值乘以100\n",
    "        return diff / norm * 100\n",
    "# 定义一个函数计算两个二值化图片矩阵的汉明距离\n",
    "def hamming_distance(img1, img2):\n",
    "    # 将图片矩阵转换为一维向量\n",
    "    vec1 = img1.flatten()\n",
    "    vec2 = img2.flatten()\n",
    "    # 计算两个向量的异或，然后统计非零元素的个数\n",
    "    diff = np.count_nonzero(vec1 ^ vec2)\n",
    "    # 返回汉明距离\n",
    "    return diff\n",
    "\n",
    "# 定义一个函数计算两个二值化图片矩阵的杰卡德相似系数\n",
    "def jaccard_similarity(img1, img2):\n",
    "    # 将图片矩阵转换为一维向量\n",
    "    vec1 = img1.flatten()\n",
    "    vec2 = img2.flatten()\n",
    "    # 计算两个向量的逻辑与，然后统计非零元素的个数（重叠区域）\n",
    "    intersection = np.count_nonzero(vec1 & vec2)\n",
    "    # 计算两个向量的逻辑或，然后统计非零元素的个数（总区域）\n",
    "    union = np.count_nonzero(vec1 | vec2)\n",
    "    # 返回杰卡德相似系数，即重叠区域除以总区域\n",
    "        # 判断总区域是否为0或接近0\n",
    "    if union < 1e-6:\n",
    "        # 返回一个特殊的值，表示无法计算相似系数\n",
    "        return -1\n",
    "    else:\n",
    "        # 返回杰卡德相似系数\n",
    "        return intersection / union\n",
    "\n",
    "# 定义一个函数计算两个二值化图片矩阵的Dice相似系数\n",
    "def dice_similarity(img1, img2):\n",
    "    # 将图片矩阵转换为一维向量\n",
    "    vec1 = img1.flatten()\n",
    "    vec2 = img2.flatten()\n",
    "    # 计算两个向量的逻辑与，然后统计非零元素的个数（重叠区域）\n",
    "    intersection = np.count_nonzero(vec1 & vec2)\n",
    "    # 计算两个向量各自的非零元素的个数之和（平均区域）\n",
    "    sum = np.count_nonzero(vec1) + np.count_nonzero(vec2)\n",
    "    # 返回Dice相似系数，即重叠区域乘以2除以平均区域\n",
    "        # 判断平均区域是否为0或接近0\n",
    "    if sum < 1e-6:\n",
    "        # 返回一个特殊的值，表示无法计算相似系数\n",
    "        return -1\n",
    "    else:\n",
    "        # 返回Dice相似系数\n",
    "        return (2 * intersection) / sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3567b3f0-392a-471b-9e5f-718a0a7be3af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
