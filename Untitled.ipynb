{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## obsoleted version(maybe useful someday...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load 2.5Dv3.py\n",
    "import os\n",
    "import shutil\n",
    "from unittest import result\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.optimizer_v2.adam import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.saving.utils_v1.mode_keys import is_train\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import imageio.v2 as imageio\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dropout, AveragePooling2D, concatenate, \\\n",
    "    GlobalAveragePooling2D, MaxPooling2D, Dense, Input\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "import zipfile\n",
    "import evalu\n",
    "import time\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "# Read datasets\n",
    "def getimg(dir,j):\n",
    "    input_dir = dir\n",
    "    img_list = []\n",
    "    for i in range(1+j,901+j):\n",
    "        filename = f'{i}.tif'\n",
    "        img_path = os.path.join(input_dir,filename)\n",
    "        img = imageio.imread(img_path)\n",
    "        img = img.astype(np.float32)\n",
    "        img = img / 255.0\n",
    "        img_list.append(img)\n",
    "    return img_list\n",
    "\n",
    "def onehot(img):\n",
    "    img = tf.cast(img, tf.int32)\n",
    "    img_one_hot = tf.one_hot(img, depth=2, on_value=1.0, off_value=0.0, axis=-1)\n",
    "    return img_one_hot\n",
    "\n",
    "def add_channel(img): \n",
    "    img = tf.expand_dims(img, axis=-1) \n",
    "    return img\n",
    "# def train_generator(label_dataset, batch_size=32):\n",
    "#     image1_datagen = ImageDataGenerator()\n",
    "#     image2_datagen = ImageDataGenerator()\n",
    "#     mask_datagen = ImageDataGenerator()\n",
    "#     seed=1\n",
    "#     def image_generator():\n",
    "#         image_generator1 = image1_datagen.flow_from_directory(\n",
    "#             '/data/caizhizheng/2D/v2/data1',\n",
    "#             # The absolute path of the data set\n",
    "#             class_mode=None,\n",
    "#             batch_size=batch_size,\n",
    "#             color_mode='grayscale',\n",
    "#             target_size=(128, 128),\n",
    "#             # save_to_dir='./data/gen/images',\n",
    "#             shuffle=False,\n",
    "#             seed=seed)\n",
    "#         image_generator2 = image2_datagen.flow_from_directory(\n",
    "#             '/data/caizhizheng/2D/v2/data2',\n",
    "#             # The absolute path of the data set\n",
    "#             class_mode=None,\n",
    "#             batch_size=batch_size,\n",
    "#             color_mode='grayscale',\n",
    "#             target_size=(128, 128),\n",
    "#             shuffle=False,\n",
    "#             # save_to_dir='./data/gen/images',\n",
    "#             seed=seed)\n",
    "#         for imgs1, imgs2 in zip(image_generator1, image_generator2):\n",
    "#             imgs1 = imgs1 / 255.0\n",
    "#             imgs2 = imgs2 / 255.0\n",
    "#             yield (imgs1, imgs2)\n",
    "            \n",
    "#     def mask_generator():\n",
    "#         for masks in mask_datagen.flow(label_dataset, batch_size=batch_size):\n",
    "#             yield masks\n",
    "    \n",
    "#     train_dataset = tf.data.Dataset.from_generator(\n",
    "#         lambda: zip(image_generator(), mask_generator()),\n",
    "#         output_types=((tf.float32, tf.float32), tf.float32),\n",
    "#         output_shapes=(((batch_size, 128, 128, 1), (batch_size, 128, 128, 1)), (batch_size, 128, 128, 2))\n",
    "#     )\n",
    "    \n",
    "#     return train_dataset\n",
    "\n",
    "\n",
    "# Draw loss curve\n",
    "def plot_history(history, result_dir, prefix):\n",
    "    \"\"\"\n",
    "    将训练与验证的accuracy与loss画出来\n",
    "    \"\"\"\n",
    "    plt.plot(history.history['accuracy'], marker='.')\n",
    "    plt.plot(history.history['val_accuracy'], marker='.')\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.grid()\n",
    "    plt.legend(['acc', 'val_acc'], loc='upper right')\n",
    "\t# plt.show()\n",
    "    plt.savefig('/code/loss_picture/unet_val_ace.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(history.history['loss'], marker='.')\n",
    "    plt.plot(history.history['val_loss'], marker='.')\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.grid()\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper right')\n",
    "    # plt.show()\n",
    "    plt.savefig('/code/loss_picture/denseunet_loss.png')\n",
    "    plt.close()\n",
    "\n",
    "    # x = history.history['loss']\n",
    "    # np.savetxt('D:/pycharm/up_down_code/loss_picture/unet_train_loss.txt', x, fmt='%f')\n",
    "    # y = history.history['val_loss']\n",
    "    # np.savetxt('D:/pycharm/up_down_code/loss_picture/unet_val_loss.txt', y, fmt='%f')hb\n",
    "\n",
    "\n",
    "def Conv_Block(input_tensor, filters, bottleneck=False, weight_decay=1e-4):\n",
    "    \"\"\"    封装卷积层\n",
    "\n",
    "    :param input_tensor: 输入张量\n",
    "    :param filters: 卷积核数目\n",
    "    :param bottleneck: 是否使用bottleneck\n",
    "    :param dropout_rate: dropout比率\n",
    "    :param weight_decay: 权重衰减率\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    concat_axis = 1 if K.image_data_format() == 'channel_first' else -1  # 确定格式\n",
    "\n",
    "    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(input_tensor)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # if bottleneck:\n",
    "    #     # 使用bottleneck进行降维\n",
    "    #     inter_channel = filters\n",
    "    #     x = Conv2D(inter_channel, (1, 1),\n",
    "    #                kernel_initializer='he_normal',\n",
    "    #                padding='same', use_bias=False,\n",
    "    #                kernel_regularizer=l2(weight_decay))(x)\n",
    "    #     x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n",
    "    #     x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters, (3, 3), kernel_initializer='he_normal', padding='same', use_bias=False)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def dens_block(input_tensor, nb_filter):\n",
    "    x1 = Conv_Block(input_tensor, nb_filter)\n",
    "    add1 = concatenate([x1, input_tensor], axis=-1)\n",
    "    x2 = Conv_Block(add1, nb_filter)\n",
    "    add2 = concatenate([x1, input_tensor, x2], axis=-1)\n",
    "    x3 = Conv_Block(add2, nb_filter)\n",
    "    return x3\n",
    "\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "# model definition\n",
    "def unet(input_shape=(128, 128, 2)):\n",
    "    # tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    # inputs = Input(input_shape)\n",
    "    input1=Input(shape=(128,128,1))\n",
    "    input2=Input(shape=(128,128,1))\n",
    "    inputs=Concatenate(axis=-1)([input1,input2])\n",
    "    # x  = Conv2D(32, 1, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = Conv2D(32, 7, kernel_initializer='he_normal', padding='same', strides=1, use_bias=False,\n",
    "               kernel_regularizer=l2(1e-4))(inputs)\n",
    "    # down first\n",
    "    down1 = dens_block(x, nb_filter=64)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(down1)  # 256\n",
    "    # down second\n",
    "    down2 = dens_block(pool1, nb_filter=64)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(down2)  # 128\n",
    "    # down third\n",
    "    down3 = dens_block(pool2, nb_filter=128)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(down3)  # 64\n",
    "    # down four\n",
    "    down4 = dens_block(pool3, nb_filter=256)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(down4)  # 32\n",
    "    # center\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    # up first\n",
    "    up6 = UpSampling2D(size=(2, 2))(drop5)\n",
    "    # up6 = UpSampling2D(size=(2, 2))(drop5)\n",
    "    add6 = concatenate([down4, up6], axis=3)\n",
    "    up6 = dens_block(add6, nb_filter=256)\n",
    "    # up second\n",
    "    up7 = UpSampling2D(size=(2, 2))(up6)\n",
    "    # up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    add7 = concatenate([down3, up7], axis=3)\n",
    "    up7 = dens_block(add7, nb_filter=128)\n",
    "    # up third\n",
    "    up8 = UpSampling2D(size=(2, 2))(up7)\n",
    "    # up8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    add8 = concatenate([down2, up8], axis=-1)\n",
    "    up8 = dens_block(add8, nb_filter=64)\n",
    "    # up four\n",
    "    up9 = UpSampling2D(size=(2, 2))(up8)\n",
    "    add9 = concatenate([down1, up9], axis=-1)\n",
    "    up9 = dens_block(add9, nb_filter=64)\n",
    "    # output\n",
    "    conv10 = Conv2D(32, 7, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(up9)\n",
    "    conv10 = Conv2D(2, 1, activation='softmax')(conv10)\n",
    "    model = Model(inputs=[input1,input2], outputs=conv10)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "# define Huber loss\n",
    "def huber_loss(y_true, y_pred):\n",
    "    return tf.losses.huber_loss(y_true, y_pred, delta=0.01)\n",
    "\n",
    "\n",
    "def simm_loss(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true)) + 0.01 * K.mean(K.abs(y_pred))\n",
    "    # return tf.abs(tf.norm(y_pred - y_true))/tf.norm(y_true)\n",
    "    \n",
    "# smooth = 1. # 用于防止分母为0.\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true) # 将 y_true 拉伸为一维.\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (K.sum(y_true_f * y_true_f) + K.sum(y_pred_f * y_pred_f))\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1. - dice_coef(y_true, y_pred)\n",
    "\n",
    "# Define the learning rate attenuation value\n",
    "def scheduler(epoch):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.1)\n",
    "        print(\"lr change to {}\".format(lr * 0.1))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "\n",
    "# ssim psnr\n",
    "from ssim import compute_ssim\n",
    "import math\n",
    "\n",
    "\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean((img1 / 255. - img2 / 255.) ** 2)\n",
    "    if mse < 1.0e-10:\n",
    "        return 100\n",
    "    PIXEL_MAX = 1\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "def add_gaussian_nois(image_in, mean=0, var=0.01):\n",
    "    \"\"\"\n",
    "    给图片添加高斯噪声\n",
    "    \"\"\"\n",
    "    img = image_in.astype(np.int16)\n",
    "    mu = 0\n",
    "    sigma = 40\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            for k in range(img.shape[2]):\n",
    "                img[i, j, k] = img[i, j, k] + random.gauss(mu=mu, sigma=sigma)\n",
    "    img[img > 255] = 255\n",
    "    img[img < 0] = 0\n",
    "    img_out = img.astype(np.uint8)\n",
    "\n",
    "    # cv2.imshow(\"noise_image\",img_out)\n",
    "    # cv2.waitKey(0)\n",
    "    return img_out\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "  0.001,\n",
    "  decay_steps=10,\n",
    "  decay_rate=1,\n",
    "  staircase=False)\n",
    "def train(model):\n",
    "    # train\n",
    "    # tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    # no shutil and shutil module\n",
    "    # logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "    # shutil.rmtree(logdir, ignore_errors=True)\n",
    "    # use tf.io.gfile\n",
    "    # logdir = tf.io.gfile.mkdir('/tensorboard_logs')\n",
    "    # tf.io.gfile.rmtree (logdir)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr_schedule), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "    # reduce_lr = LearningRateScheduler(scheduler)\n",
    "    # reduce_lr = LearningRateScheduler(lschedule)\n",
    "    model_checkpoint = ModelCheckpoint('/code/save_model/'+model_savename, monitor='loss', verbose=1,\n",
    "                                       save_best_only=True)\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "    Board = tf.keras.callbacks.TensorBoard(log_dir=\"/output/logs\")\n",
    "\n",
    "    history = model.fit(train_dataset.repeat(),\n",
    "                                  steps_per_epoch=100,\n",
    "                                  epochs=400,\n",
    "                                  validation_data=validation_dataset,\n",
    "                                #   validation_steps=50,\n",
    "                                  callbacks=[model_checkpoint,\n",
    "                                             early_stop,Board\n",
    "                                             ])\n",
    "    plot_history(history, '.results/', 'Unet')\n",
    "    return model\n",
    "\n",
    "def test(model):\n",
    "    # test\n",
    "    input_dir = '/data/caizhizheng/2D/v2/predicted_input_data'\n",
    "    for i in range(1,101):\n",
    "        # x = cv2.imread('/data/caizhizheng/data/test/%d.tif' % (i))  # #The absolute path of the testsets\n",
    "        # x = add_gaussian_nois(x)\n",
    "        # x = cv2.cvtColor(x,cv2.COLOR_BGR2GRAY)\n",
    "        filename1 = f'{i}.tif'\n",
    "        img_path1 = os.path.join(input_dir,filename1)\n",
    "        x1 = cv2.imread(img_path1, cv2.IMREAD_GRAYSCALE)\n",
    "        x1 = x1 / 255.0\n",
    "        x1 = np.array([x1])\n",
    "        filename2 = f'{i+100}.tif'\n",
    "        img_path2 = os.path.join(input_dir,filename2)\n",
    "        x2 = cv2.imread(img_path2, cv2.IMREAD_GRAYSCALE)\n",
    "        x2 = x2 / 255.0\n",
    "        x2 = np.array([x2])\n",
    "        # xt = np.stack([x1, x2], axis=-1)\n",
    "        mask_tensor = model.predict([x1,x2], batch_size=None, verbose=0, steps=None)\n",
    "        mask = mask_tensor[0]\n",
    "        mask = tf.argmax(mask, axis=-1)\n",
    "        mask = tf.keras.backend.eval(mask)\n",
    "        mask = (mask * 255).astype(np.uint8)\n",
    "        cv2.imwrite('/data/caizhizheng/2D/v2/result/%d.tif' % (i), mask)\n",
    "        \n",
    "def make_zip(source_dir, output_name):\n",
    "    zipf = zipfile.ZipFile(output_name, 'w')\n",
    "    prelen = len(os.path.dirname(source_dir))\n",
    "    for parent, _, filenames in os.walk(source_dir):\n",
    "        for filename in filenames:\n",
    "            pathfile = os.path.join(parent, filename)\n",
    "            arcname = pathfile[prelen:].strip(os.path.sep)     #相对路径\n",
    "            zipf.write(pathfile, arcname)\n",
    "        zipf.close()\n",
    "BATCH_SIZE=128\n",
    "if __name__ == '__main__':\n",
    "    # is_train = False # you can change this to False if you want to test only\n",
    "    model = unet(input_shape=(128, 128, 2))\n",
    "    # model = tf.keras.models.load_model('/code/save_model/dens_2.5Dv3.keras')\n",
    "    # if is_train:\n",
    "    label_list=getimg(dir='/data/caizhizheng/2D/v2/label/label',j=0)\n",
    "    label_dataset = tf.data.Dataset.from_tensor_slices(label_list)\n",
    "    label_dataset = label_dataset.map(onehot)\n",
    "    img1_list=getimg(dir='/data/caizhizheng/2D/v2/data1/data',j=0)\n",
    "    img1_dataset = tf.data.Dataset.from_tensor_slices(img1_list)\n",
    "    # img1_dataset = img1_dataset.map(add_channel)\n",
    "    img2_list=getimg(dir='/data/caizhizheng/2D/v2/data2/data',j=900)\n",
    "    img2_dataset = tf.data.Dataset.from_tensor_slices(img2_list)\n",
    "    # img2_dataset = img2_dataset.map(add_channel)\n",
    "    image_dataset = tf.data.Dataset.zip((img1_dataset, img2_dataset))\n",
    "    train_dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "    #4th modifation\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=len(train_dataset))\n",
    "    validation_dataset = train_dataset.take(32).cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    train_dataset = train_dataset.skip(32).cache()\n",
    "    \n",
    "    # train_dataset = train_dataset.cache()\n",
    "    train_dataset = train_dataset.shuffle(BATCH_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    # train_dataset = train_dataset.batch(32)\n",
    "    time1 = time.strftime('%m%d%H')\n",
    "    model_savename = 'dens_2.5Dv3' + time1 +'.keras'\n",
    "    result_name = 'result' + time1 + '.zip'\n",
    "    source_dir = \"/data/caizhizheng/2D/v2/result\"\n",
    "    output_name = \"/data/caizhizheng/2D/v2/\"+result_name\n",
    "    model = train(model) # train the model and save the best weights\n",
    "    # else:\n",
    "    # model.load_weights('/code/save_model/dens_2.5Dv3.keras') # load the saved weights\n",
    "    test(model) # test the model and save the results\n",
    "\n",
    "    make_zip(source_dir=source_dir, output_name=output_name)\n",
    "    print(\"zip OK\")\n",
    "    evalu.main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e49b0a9bd22a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "mask = tf.keras.backend.eval(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 交叉验证测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import os\n",
    "import shutil\n",
    "from unittest import result\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.optimizer_v2.adam import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.saving.utils_v1.mode_keys import is_train\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import imageio.v2 as imageio\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dropout, AveragePooling2D, concatenate, \\\n",
    "    GlobalAveragePooling2D, MaxPooling2D, Dense, Input\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import zipfile\n",
    "import evalu\n",
    "import time\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "# Read datasets\n",
    "def getimg(dir,j):\n",
    "    input_dir = dir\n",
    "    img_list = []\n",
    "    for i in range(1+j,901+j):\n",
    "        filename = f'{i}.tif'\n",
    "        img_path = os.path.join(input_dir,filename)\n",
    "        img = imageio.imread(img_path)\n",
    "        img = img.astype(np.float32)\n",
    "        img = img / 255.0\n",
    "        img_list.append(img)\n",
    "    return img_list\n",
    "\n",
    "def onehot(img):\n",
    "    img = tf.cast(img, tf.int32)\n",
    "    img_one_hot = tf.one_hot(img, depth=2, on_value=1.0, off_value=0.0, axis=-1)\n",
    "    return img_one_hot\n",
    "\n",
    "def add_channel(img): \n",
    "    img = tf.expand_dims(img, axis=-1) \n",
    "    return img\n",
    "# Draw loss curve\n",
    "def plot_history(history, result_dir, prefix):\n",
    "    \"\"\"\n",
    "    将训练与验证的accuracy与loss画出来\n",
    "    \"\"\"\n",
    "    plt.plot(history.history['accuracy'], marker='.')\n",
    "    plt.plot(history.history['val_accuracy'], marker='.')\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.grid()\n",
    "    plt.legend(['acc', 'val_acc'], loc='upper right')\n",
    "\t# plt.show()\n",
    "    plt.savefig('/code/loss_picture/unet_val_ace.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(history.history['loss'], marker='.')\n",
    "    plt.plot(history.history['val_loss'], marker='.')\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.grid()\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper right')\n",
    "    # plt.show()\n",
    "    plt.savefig('/code/loss_picture/denseunet_loss.png')\n",
    "    plt.close()\n",
    "\n",
    "    # x = history.history['loss']\n",
    "    # np.savetxt('D:/pycharm/up_down_code/loss_picture/unet_train_loss.txt', x, fmt='%f')\n",
    "    # y = history.history['val_loss']\n",
    "    # np.savetxt('D:/pycharm/up_down_code/loss_picture/unet_val_loss.txt', y, fmt='%f')hb\n",
    "\n",
    "\n",
    "def Conv_Block(input_tensor, filters, bottleneck=False, weight_decay=1e-4):\n",
    "    \"\"\"    封装卷积层\n",
    "\n",
    "    :param input_tensor: 输入张量\n",
    "    :param filters: 卷积核数目\n",
    "    :param bottleneck: 是否使用bottleneck\n",
    "    :param dropout_rate: dropout比率\n",
    "    :param weight_decay: 权重衰减率\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    concat_axis = 1 if K.image_data_format() == 'channel_first' else -1  # 确定格式\n",
    "\n",
    "    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(input_tensor)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # if bottleneck:\n",
    "    #     # 使用bottleneck进行降维\n",
    "    #     inter_channel = filters\n",
    "    #     x = Conv2D(inter_channel, (1, 1),\n",
    "    #                kernel_initializer='he_normal',\n",
    "    #                padding='same', use_bias=False,\n",
    "    #                kernel_regularizer=l2(weight_decay))(x)\n",
    "    #     x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n",
    "    #     x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters, (3, 3), kernel_initializer='he_normal', padding='same', use_bias=False)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def dens_block(input_tensor, nb_filter):\n",
    "    x1 = Conv_Block(input_tensor, nb_filter)\n",
    "    add1 = concatenate([x1, input_tensor], axis=-1)\n",
    "    x2 = Conv_Block(add1, nb_filter)\n",
    "    add2 = concatenate([x1, input_tensor, x2], axis=-1)\n",
    "    x3 = Conv_Block(add2, nb_filter)\n",
    "    return x3\n",
    "\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "# model definition\n",
    "def unet(input_shape=(128, 128, 2)):\n",
    "    # tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    inputs = Input(input_shape)\n",
    "    # input1=Input(shape=(128,128,1))\n",
    "    # input2=Input(shape=(128,128,1))\n",
    "    # inputs=Concatenate(axis=-1)([input1,input2])\n",
    "    # inputs = Input(shape\n",
    "    # x  = Conv2D(32, 1, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = Conv2D(32, 7, kernel_initializer='he_normal', padding='same', strides=1, use_bias=False,\n",
    "               kernel_regularizer=l2(1e-4))(inputs)\n",
    "    # down first\n",
    "    down1 = dens_block(x, nb_filter=64)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(down1)  # 256\n",
    "    # down second\n",
    "    down2 = dens_block(pool1, nb_filter=64)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(down2)  # 128\n",
    "    # down third\n",
    "    down3 = dens_block(pool2, nb_filter=128)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(down3)  # 64\n",
    "    # down four\n",
    "    down4 = dens_block(pool3, nb_filter=256)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(down4)  # 32\n",
    "    # center\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    # up first\n",
    "    up6 = UpSampling2D(size=(2, 2))(drop5)\n",
    "    # up6 = UpSampling2D(size=(2, 2))(drop5)\n",
    "    add6 = concatenate([down4, up6], axis=3)\n",
    "    up6 = dens_block(add6, nb_filter=256)\n",
    "    # up second\n",
    "    up7 = UpSampling2D(size=(2, 2))(up6)\n",
    "    # up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    add7 = concatenate([down3, up7], axis=3)\n",
    "    up7 = dens_block(add7, nb_filter=128)\n",
    "    # up third\n",
    "    up8 = UpSampling2D(size=(2, 2))(up7)\n",
    "    # up8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    add8 = concatenate([down2, up8], axis=-1)\n",
    "    up8 = dens_block(add8, nb_filter=64)\n",
    "    # up four\n",
    "    up9 = UpSampling2D(size=(2, 2))(up8)\n",
    "    add9 = concatenate([down1, up9], axis=-1)\n",
    "    up9 = dens_block(add9, nb_filter=64)\n",
    "    # output\n",
    "    conv10 = Conv2D(32, 7, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(up9)\n",
    "    conv10 = Conv2D(2, 1, activation='softmax')(conv10)\n",
    "    # model = Model(inputs=[input1,input2], outputs=conv10)\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "# define Huber loss\n",
    "def huber_loss(y_true, y_pred):\n",
    "    return tf.losses.huber_loss(y_true, y_pred, delta=0.01)\n",
    "\n",
    "\n",
    "def simm_loss(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true)) + 0.01 * K.mean(K.abs(y_pred))\n",
    "    # return tf.abs(tf.norm(y_pred - y_true))/tf.norm(y_true)\n",
    "    \n",
    "# smooth = 1. # 用于防止分母为0.\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true) # 将 y_true 拉伸为一维.\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (K.sum(y_true_f * y_true_f) + K.sum(y_pred_f * y_pred_f))\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1. - dice_coef(y_true, y_pred)\n",
    "\n",
    "# Define the learning rate attenuation value\n",
    "def scheduler(epoch):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.1)\n",
    "        print(\"lr change to {}\".format(lr * 0.1))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean((img1 / 255. - img2 / 255.) ** 2)\n",
    "    if mse < 1.0e-10:\n",
    "        return 100\n",
    "    PIXEL_MAX = 1\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "def add_gaussian_nois(image_in, mean=0, var=0.01):\n",
    "    \"\"\"\n",
    "    给图片添加高斯噪声\n",
    "    \"\"\"\n",
    "    img = image_in.astype(np.int16)\n",
    "    mu = 0\n",
    "    sigma = 40\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            for k in range(img.shape[2]):\n",
    "                img[i, j, k] = img[i, j, k] + random.gauss(mu=mu, sigma=sigma)\n",
    "    img[img > 255] = 255\n",
    "    img[img < 0] = 0\n",
    "    img_out = img.astype(np.uint8)\n",
    "\n",
    "    # cv2.imshow(\"noise_image\",img_out)\n",
    "    # cv2.waitKey(0)\n",
    "    return img_out\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "  0.001,\n",
    "  decay_steps=10,\n",
    "  decay_rate=1,\n",
    "  staircase=False)\n",
    "def train(model):\n",
    "    # train\n",
    "    # tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    # no shutil and shutil module\n",
    "    # logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "    # shutil.rmtree(logdir, ignore_errors=True)\n",
    "    # use tf.io.gfile\n",
    "    # logdir = tf.io.gfile.mkdir('/tensorboard_logs')\n",
    "    # tf.io.gfile.rmtree (logdir)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr_schedule), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "    # reduce_lr = LearningRateScheduler(scheduler)\n",
    "    # reduce_lr = LearningRateScheduler(lschedule)\n",
    "    model_checkpoint = ModelCheckpoint('/code/save_model/'+model_savename, monitor='loss', verbose=1,\n",
    "                                       save_best_only=True)\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "    Board = tf.keras.callbacks.TensorBoard(log_dir=\"/output/logs\")\n",
    "\n",
    "    history = model.fit(train_dataset.repeat(),\n",
    "                                  steps_per_epoch=100,\n",
    "                                  epochs=400,\n",
    "                                  validation_data=validation_dataset,\n",
    "                                #   validation_steps=50,\n",
    "                                  callbacks=[model_checkpoint,\n",
    "                                             early_stop,Board\n",
    "                                             ])\n",
    "    plot_history(history, '.results/', 'Unet')\n",
    "    return model\n",
    "\n",
    "def test(model):\n",
    "    # test\n",
    "    input_dir = '/data/caizhizheng/2D/v2/predicted_input_data'\n",
    "    for i in range(1,101):\n",
    "        # x = cv2.imread('/data/caizhizheng/data/test/%d.tif' % (i))  # #The absolute path of the testsets\n",
    "        # x = add_gaussian_nois(x)\n",
    "        # x = cv2.cvtColor(x,cv2.COLOR_BGR2GRAY)\n",
    "        filename1 = f'{i}.tif'\n",
    "        img_path1 = os.path.join(input_dir,filename1)\n",
    "        x1 = cv2.imread(img_path1, cv2.IMREAD_GRAYSCALE)\n",
    "        x1 = x1 / 255.0\n",
    "        x1 = np.array([x1])\n",
    "        filename2 = f'{i+100}.tif'\n",
    "        img_path2 = os.path.join(input_dir,filename2)\n",
    "        x2 = cv2.imread(img_path2, cv2.IMREAD_GRAYSCALE)\n",
    "        x2 = x2 / 255.0\n",
    "        x2 = np.array([x2])\n",
    "        # xt = np.stack([x1, x2], axis=-1)\n",
    "        mask_tensor = model.predict([x1,x2], batch_size=None, verbose=0, steps=None)\n",
    "        mask = mask_tensor[0]\n",
    "        mask = tf.argmax(mask, axis=-1)\n",
    "        mask = tf.keras.backend.eval(mask)\n",
    "        mask = (mask * 255).astype(np.uint8)\n",
    "        cv2.imwrite('/data/caizhizheng/2D/v2/result/%d.tif' % (i), mask)\n",
    "        \n",
    "def make_zip(source_dir, output_name):\n",
    "    zipf = zipfile.ZipFile(output_name, 'w')\n",
    "    prelen = len(os.path.dirname(source_dir))\n",
    "    for parent, _, filenames in os.walk(source_dir):\n",
    "        for filename in filenames:\n",
    "            pathfile = os.path.join(parent, filename)\n",
    "            arcname = pathfile[prelen:].strip(os.path.sep)     #相对路径\n",
    "            zipf.write(pathfile, arcname)\n",
    "        zipf.close()\n",
    "BATCH_SIZE=16\n",
    "if __name__ == '__main__':\n",
    "    # is_train = False # you can change this to False if you want to test only\n",
    "    model = unet(input_shape=(128, 128, 2))\n",
    "    model.compile(optimizer=Adam(learning_rate=lr_schedule), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "    # model_checkpoint = ModelCheckpoint('/code/save_model/'+model_savename, monitor='loss', verbose=1,\n",
    "    #                                    save_best_only=True)\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "    Board = tf.keras.callbacks.TensorBoard(log_dir=\"/output/logs\")\n",
    "    # model = tf.keras.models.load_model('/code/save_model/dens_2.5Dv3.keras')\n",
    "    # if is_train:\n",
    "    # label_list=getimg(dir='/data/caizhizheng/2D/v2/label/label',j=0)\n",
    "    # label_dataset = tf.data.Dataset.from_tensor_slices(label_list)\n",
    "    # label_dataset = label_dataset.map(onehot)\n",
    "    # img1_list=getimg(dir='/data/caizhizheng/2D/v2/data1/data',j=0)\n",
    "    # img1_dataset = tf.data.Dataset.from_tensor_slices(img1_list)\n",
    "    # # img1_dataset = img1_dataset.map(add_channel)\n",
    "    # img2_list=getimg(dir='/data/caizhizheng/2D/v2/data2/data',j=900)\n",
    "    # img2_dataset = tf.data.Dataset.from_tensor_slices(img2_list)\n",
    "    # # img2_dataset = img2_dataset.map(add_channel)\n",
    "    # image_dataset = tf.data.Dataset.zip((img1_dataset, img2_dataset))\n",
    "    # train_dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "    # image_dataset = tf.data.experimental.load(\"dataset/data\")\n",
    "    # label_dataset = tf.data.experimental.load(\"dataset/label\")\n",
    "    # image_dataset1 = image_dataset.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    # label_dataset1 = label_dataset.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    # train_dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "    # train_dataset1 = train_dataset.repeat(400).cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    #4th modifation\n",
    "    # train_dataset1 = train_dataset.shuffle(buffer_size=len(train_dataset))\n",
    "    # validation_dataset = train_dataset.take(32).cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    # train_dataset2 = train_dataset1.skip(32).cache()   \n",
    "    # train_dataset2 = train_dataset2.shuffle(BATCH_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # model = train(model) # train the model and save the best weights\n",
    "    # 也许可以参考scikeras这个包\n",
    "    # model = KerasClassifier(build_fn=model, epochs=400, loss=, )\n",
    "    \n",
    "    # kf = KFold(n_splits=10, shuffle = True)\n",
    "    # fold_no = 1\n",
    "    # for train, test in kf.split(train_dataset1):\n",
    "    #     model_savename = 'dens_2.5Dv3' + str(fold_no) +'.keras'\n",
    "    #     model_checkpoint = ModelCheckpoint('/code/save_model/'+model_savename, monitor='loss', verbose=1,\n",
    "    #                                    save_best_only=True)\n",
    "    #     history = model.fit(image_dataset.repeat(), label_dataset.repeat(), \n",
    "    #                               steps_per_epoch=100,\n",
    "    #                               epochs=400,\n",
    "    #                               # validation_data=validation_dataset,\n",
    "    #                             #   validation_steps=50,\n",
    "    #                               callbacks=[model_checkpoint,\n",
    "    #                                          early_stop,Board\n",
    "    #                                          ])\n",
    "        \n",
    "    #     fold_no = fold_no +1\n",
    "        \n",
    "    # else:    \n",
    "    # train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "    # model.load_weights('/code/save_model/dens_2.5Dv3.keras') # load the saved weights\n",
    "    # mask = model.predict(train_dataset)\n",
    "    # # mask = maskb[0]\n",
    "    # mask1 = tf.argmax(mask, axis=-1)\n",
    "    # mask2 = tf.keras.backend.eval(mask1)\n",
    "    # mask3 = (mask2 * 255).astype(np.uint8)\n",
    "    # for i in range(0, len(mask)+1):\n",
    "    #     cv2.imwrite('/data/caizhizheng/2D/v2/result/%d.tif' % (i), mask[i])\n",
    "    # # # test(model) # test the model and save the results\n",
    "    # # time1 = time.strftime('%m%d%H')\n",
    "    # # model_savename = 'dens_2.5Dv3' + time1 +'.keras'\n",
    "    # # result_name = 'result' + time1 + '.zip'\n",
    "    # # source_dir = \"/data/caizhizheng/2D/v2/result\"\n",
    "    # # output_name = \"/data/caizhizheng/2D/v2/\"+result_name\n",
    "    # # make_zip(source_dir=source_dir, output_name=output_name)\n",
    "    # print(\"zip OK\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 128, 128, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(list(xx_dataset.take(2).as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 us, sys: 0 ns, total: 14 us\n",
      "Wall time: 27.7 us\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "image_dataset1 = tf.data.experimental.load(\"dataset/data1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 us, sys: 7 us, total: 12 us\n",
      "Wall time: 22.2 us\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "img1_list=getimg(dir='/data/caizhizheng/2D/v2/data1/data',j=0)\n",
    "img1_dataset = tf.data.Dataset.from_tensor_slices(img1_list)\n",
    "img1_dataset = img1_dataset.map(add_channel)\n",
    "img2_list=getimg(dir='/data/caizhizheng/2D/v2/data2/data',j=900)\n",
    "img2_dataset = tf.data.Dataset.from_tensor_slices(img2_list)\n",
    "img2_dataset = img2_dataset.map(add_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.stack((img1_list,img2_list),axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (128, 128, 2), types: tf.float32>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx_dataset = tf.data.Dataset.from_tensor_slices(xx)\n",
    "xx_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(image_dataset1.batch(image_dataset1.cardinality().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = next(iter(label_dataset.batch(label_dataset.cardinality().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 us, sys: 9 us, total: 25 us\n",
      "Wall time: 40.3 us\n",
      "Epoch 1/400\n",
      " 20/100 [=====>........................] - ETA: 26:10 - loss: 0.6803 - accuracy: 0.650 - ETA: 20:31 - loss: 1.2210 - accuracy: 0.688 - ETA: 19:32 - loss: 0.9616 - accuracy: 0.718 - ETA: 18:50 - loss: 0.8875 - accuracy: 0.689 - ETA: 18:42 - loss: 0.8370 - accuracy: 0.695 - ETA: 18:27 - loss: 0.7678 - accuracy: 0.713 - ETA: 18:09 - loss: 0.7567 - accuracy: 0.708 - ETA: 17:55 - loss: 0.7061 - accuracy: 0.723 - ETA: 17:39 - loss: 0.6775 - accuracy: 0.731 - ETA: 17:27 - loss: 0.6506 - accuracy: 0.743 - ETA: 17:17 - loss: 0.6220 - accuracy: 0.751 - ETA: 17:06 - loss: 0.6051 - accuracy: 0.757 - ETA: 16:50 - loss: 0.5868 - accuracy: 0.762 - ETA: 16:39 - loss: 0.5760 - accuracy: 0.766 - ETA: 16:27 - loss: 0.5646 - accuracy: 0.772 - ETA: 16:16 - loss: 0.5506 - accuracy: 0.778 - ETA: 16:01 - loss: 0.5437 - accuracy: 0.778 - ETA: 15:50 - loss: 0.5376 - accuracy: 0.779 - ETA: 15:38 - loss: 0.5255 - accuracy: 0.782 - ETA: 15:27 - loss: 0.5145 - accuracy: 0.7870"
     ]
    }
   ],
   "source": [
    "%time\n",
    "kf = KFold(n_splits=10)\n",
    "for train_index, test_index in kf.split(x,y):\n",
    "    x_train, x_test = tf.gather(x, train_index), tf.gather(x, test_index)\n",
    "    y_train, y_test = tf.gather(y, train_index), tf.gather(y, test_index)\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    vali_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    train_dataset = train_dataset.cache().shuffle(train_dataset.cardinality()).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    vali_dataset = vali_dataset.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    model_savename = 'dens_2.5Dv3' + str(fold_no) +'.keras'\n",
    "    model_checkpoint = ModelCheckpoint('/code/save_model/'+model_savename, monitor='loss', verbose=1,\n",
    "                                       save_best_only=True)\n",
    "    history = model.fit(train_dataset, \n",
    "                                  steps_per_epoch=100,\n",
    "                                  epochs=400,\n",
    "                                  validation_data=vali_dataset,\n",
    "                                #   validation_steps=50,\n",
    "                                  callbacks=[model_checkpoint,\n",
    "                                             early_stop,Board\n",
    "                                             ])\n",
    "        \n",
    "    fold_no = fold_no +1\n",
    "    \n",
    "    # x_test, x_test = x[test_index], y[test_index]\n",
    "    # print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = tf.data.experimental.load(\"dataset/data1\")\n",
    "test_set = test_set.batch(32) \n",
    "weight_path = '/code/save_model/CrossVali/CrossVali1.keras'\n",
    "model.load_weights(weight_path)\n",
    "mask = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 128, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1 = tf.argmax(mask, axis=-1)\n",
    "mask2 = tf.keras.backend.eval(mask1)\n",
    "mask2 = (mask2 * 255).astype(np.uint8)\n",
    "mask2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = '/data/caizhizheng/2D/CRV/1/'\n",
    "os.makedirs(write_path, exist_ok=True)\n",
    "for i in range(0, len(mask2)):\n",
    "    cv2.imwrite(write_path+ '%d.tif' %(i+1), mask2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均汉明距离为：185.3567\n",
      "平均杰卡德相似系数为：0.8933\n",
      "平均Dice相似系数为：0.9285\n",
      "平均误差为：26.6872%\n"
     ]
    }
   ],
   "source": [
    "import evalu\n",
    "write_path = '/data/caizhizheng/2D/CRV/1/'\n",
    "error_path = '/data/caizhizheng/2D/CRV/errors/'\n",
    "evalu.main(output_dir=write_path, label_dir='/data/caizhizheng/2D/v2/label/label/', name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均汉明距离为：185.3567\n",
      "平均杰卡德相似系数为：0.8933\n",
      "平均Dice相似系数为：0.9285\n",
      "平均误差为：26.6872%\n",
      "Fold1 model test complete\n",
      "平均汉明距离为：228.4422\n",
      "平均杰卡德相似系数为：0.8754\n",
      "平均Dice相似系数为：0.9144\n",
      "平均误差为：29.6329%\n",
      "Fold2 model test complete\n",
      "平均汉明距离为：385.7944\n",
      "平均杰卡德相似系数为：0.8113\n",
      "平均Dice相似系数为：0.8647\n",
      "平均误差为：37.9961%\n",
      "Fold3 model test complete\n",
      "平均汉明距离为：385.3267\n",
      "平均杰卡德相似系数为：0.8153\n",
      "平均Dice相似系数为：0.8656\n",
      "平均误差为：36.8436%\n",
      "Fold4 model test complete\n",
      "平均汉明距离为：383.0878\n",
      "平均杰卡德相似系数为：0.8462\n",
      "平均Dice相似系数为：0.8962\n",
      "平均误差为：35.6835%\n",
      "Fold5 model test complete\n",
      "平均汉明距离为：86.1111\n",
      "平均杰卡德相似系数为：0.9327\n",
      "平均Dice相似系数为：0.9523\n",
      "平均误差为：17.3221%\n",
      "Fold6 model test complete\n",
      "平均汉明距离为：296.1267\n",
      "平均杰卡德相似系数为：0.8697\n",
      "平均Dice相似系数为：0.9100\n",
      "平均误差为：30.3850%\n",
      "Fold7 model test complete\n",
      "平均汉明距离为：311.8744\n",
      "平均杰卡德相似系数为：0.8523\n",
      "平均Dice相似系数为：0.8986\n",
      "平均误差为：32.7636%\n",
      "Fold8 model test complete\n",
      "平均汉明距离为：138.3322\n",
      "平均杰卡德相似系数为：0.9196\n",
      "平均Dice相似系数为：0.9438\n",
      "平均误差为：21.3420%\n",
      "Fold9 model test complete\n",
      "平均汉明距离为：114.8244\n",
      "平均杰卡德相似系数为：0.9184\n",
      "平均Dice相似系数为：0.9409\n",
      "平均误差为：20.1036%\n",
      "Fold10 model test complete\n"
     ]
    }
   ],
   "source": [
    "# %load CrV_pred.py\n",
    "# almost same except in the last lines...\n",
    "import os \n",
    "import evalu\n",
    "from unittest import result\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.optimizer_v2.adam import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.saving.utils_v1.mode_keys import is_train\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import imageio.v2 as imageio\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dropout, AveragePooling2D, concatenate, \\\n",
    "    GlobalAveragePooling2D, MaxPooling2D, Dense, Input\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def Conv_Block(input_tensor, filters, bottleneck=False, weight_decay=1e-4):\n",
    "    \"\"\"    封装卷积层\n",
    "\n",
    "    :param input_tensor: 输入张量\n",
    "    :param filters: 卷积核数目\n",
    "    :param bottleneck: 是否使用bottleneck\n",
    "    :param dropout_rate: dropout比率\n",
    "    :param weight_decay: 权重衰减率\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    concat_axis = 1 if K.image_data_format() == 'channel_first' else -1  # 确定格式\n",
    "\n",
    "    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(input_tensor)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # if bottleneck:\n",
    "    #     # 使用bottleneck进行降维\n",
    "    #     inter_channel = filters\n",
    "    #     x = Conv2D(inter_channel, (1, 1),\n",
    "    #                kernel_initializer='he_normal',\n",
    "    #                padding='same', use_bias=False,\n",
    "    #                kernel_regularizer=l2(weight_decay))(x)\n",
    "    #     x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n",
    "    #     x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters, (3, 3), kernel_initializer='he_normal', padding='same', use_bias=False)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def dens_block(input_tensor, nb_filter):\n",
    "    x1 = Conv_Block(input_tensor, nb_filter)\n",
    "    add1 = concatenate([x1, input_tensor], axis=-1)\n",
    "    x2 = Conv_Block(add1, nb_filter)\n",
    "    add2 = concatenate([x1, input_tensor, x2], axis=-1)\n",
    "    x3 = Conv_Block(add2, nb_filter)\n",
    "    return x3\n",
    "    \n",
    "def unet(input_shape=(128, 128, 2)):\n",
    "    # tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    inputs = Input(input_shape)\n",
    "    # x  = Conv2D(32, 1, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = Conv2D(32, 7, kernel_initializer='he_normal', padding='same', strides=1, use_bias=False,\n",
    "               kernel_regularizer=l2(1e-4))(inputs)\n",
    "    # down first\n",
    "    down1 = dens_block(x, nb_filter=64)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(down1)  # 256\n",
    "    # down second\n",
    "    down2 = dens_block(pool1, nb_filter=64)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(down2)  # 128\n",
    "    # down third\n",
    "    down3 = dens_block(pool2, nb_filter=128)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(down3)  # 64\n",
    "    # down four\n",
    "    down4 = dens_block(pool3, nb_filter=256)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(down4)  # 32\n",
    "    # center\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    # up first\n",
    "    up6 = UpSampling2D(size=(2, 2))(drop5)\n",
    "    # up6 = UpSampling2D(size=(2, 2))(drop5)\n",
    "    add6 = concatenate([down4, up6], axis=3)\n",
    "    up6 = dens_block(add6, nb_filter=256)\n",
    "    # up second\n",
    "    up7 = UpSampling2D(size=(2, 2))(up6)\n",
    "    # up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    add7 = concatenate([down3, up7], axis=3)\n",
    "    up7 = dens_block(add7, nb_filter=128)\n",
    "    # up third\n",
    "    up8 = UpSampling2D(size=(2, 2))(up7)\n",
    "    # up8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    add8 = concatenate([down2, up8], axis=-1)\n",
    "    up8 = dens_block(add8, nb_filter=64)\n",
    "    # up four\n",
    "    up9 = UpSampling2D(size=(2, 2))(up8)\n",
    "    add9 = concatenate([down1, up9], axis=-1)\n",
    "    up9 = dens_block(add9, nb_filter=64)\n",
    "    # output\n",
    "    conv10 = Conv2D(32, 7, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(up9)\n",
    "    conv10 = Conv2D(2, 1, activation='softmax')(conv10)\n",
    "    # model = Model(inputs=[input1,input2], outputs=conv10)\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    # print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "model = unet(input_shape=(128, 128, 2))\n",
    "\n",
    "write_path = '/data/caizhizheng/2D/CRV/'\n",
    "error_path = '/data/caizhizheng/2D/CRV/errors/'\n",
    "\n",
    "test_set = tf.data.experimental.load(\"dataset/data1\")\n",
    "test_set = test_set.batch(32) \n",
    "for i in range(1,11):\n",
    "    weight_path = '/code/save_model/CrossVali/CrossVali' + str(i) + '.keras'\n",
    "    model.load_weights(weight_path)\n",
    "    mask = model.predict(test_set)\n",
    "    mask = tf.argmax(mask, axis=-1)\n",
    "    mask = tf.keras.backend.eval(mask)\n",
    "    mask = (mask * 255).astype(np.uint8)\n",
    "    write_path1 = write_path + str(i)\n",
    "    os.makedirs(write_path1, exist_ok=True)\n",
    "    for j in range(0, len(mask)):\n",
    "        cv2.imwrite(write_path1+'/'+ '%d.tif' %(j+1), mask[j])\n",
    "    name = 'error' + str(i) + '.csv'\n",
    "    name = os.path.join(error_path, name)\n",
    "    evalu.main(output_dir=write_path1+'/', label_dir='/data/caizhizheng/2D/v2/label/label/', name = name)\n",
    "    print(f'Fold{i} model test complete')\n",
    "    # 以Dice来看，优劣依次为6，9，10，1，2，7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 交叉验证两个思路\n",
    "repeat之后转化成numpy数组，再在KFold里面处理，问题：可能爆内存，验证集的val_loss不知道能不能自动完成\n",
    "\n",
    "用datset.window划分成多个，但是每个不像数组那样好调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ii = image_dataset.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "iii = image_dataset.window(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((128, 128), (128, 128)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.snapshot(path=path,compression='AUTO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存snapsho\n",
    "x = image_dataset.snapshot(\"save_data\")\n",
    "xx = x.take(5)\n",
    "for element in xx:\n",
    "    print(element)\n",
    "# path = '/code/save_data'\n",
    "# x.snapshot(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "ioj = ioj.snapshot(\"save_data/9833064696776558066\", shard_func=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 51 us, total: 51 us\n",
      "Wall time: 92 us\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "train_dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "train_dataset1 = train_dataset.repeat(400).cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# i = tf.data.experimental.load(\"dataset/data\")\n",
    "tf.TensorSpec(label_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试使用load 读取snapshot\n",
    "import pickle\n",
    "path = \"save_data\"\n",
    "# with open(path, \"rb\") as in_:\n",
    "#     element_spec = pickle.load(in_)\n",
    "i = tf.data.experimental.load(path,element_spec=tf.TensorSpec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f91201a7940>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(mask1[0])\n",
    "plt.colorbar()\n",
    "# 很好， 不shuffle顺序是一致的\n",
    "# 以后如果顺序不一致再问bing dataset可能的name属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mask2[0].flatten()\n",
    "for i in range(0,len(x)):\n",
    "    print(x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'ModuleNotFoundError'>",
     "evalue": "No module named 'scikeras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/xpython_1244/1290008699.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscikeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scikeras'"
     ]
    }
   ],
   "source": [
    "import scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.16"
  },
  "toc-autonumbering": true,
  "toc-showtags": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
